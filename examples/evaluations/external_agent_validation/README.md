# Validating and Evaluating External Agents

## Validation

The `external_validate` command validates your external agent to the chat completions schema for streamed events.
The `external_validate` command stores validation results including the streamed events from the external agent for later triaging and debugging.

### Running Validation
1. Prepare an external agent following the [chat-completions spec](https://github.com/watson-developer-cloud/watsonx-orchestrate-developer-toolkit/tree/main/external_agent).
2. Create an external agent spec for your external agent. See the [documentation](https://developer.watson-orchestrate.ibm.com/agents/build_agent#provider%3A-external-chat) on how to create a spec for an *external-chat* external agent. There is an example provided in `examples/evaluations/external_agent_validation/sample.yaml` as a reference.
3. Prepare a TSV with two columns. The first column contains user stories. The second column is the expected summary or output. See `examples/evaluations/external_agent_validation/test.tsv`
4. The user stories are passed to the external agent to validate the events generated by the external agent adhere to the chat-completions schema.
```bash
orchestrate evaluations validate-external --tsv ./examples/evaluations/external_agent_validation/test.tsv --external-agent-config ./examples/evaluations/external_agent_validation/sample.yaml --credential "<API/BEARER TOKEN>"
```
5. The validation results are saved to a `validation_results` subfolder under the path provided for the `--output` flag.

ðŸš¨ Note: we expect `WATSONX_APIKEY, WATSONX_SPACE_ID` or `WO_INSTANCE, WO_API_KEY` be part of the environment variables or specified in .env_file. 

### Analyzing the Results
There are two files created:

1. `sample_block_validation_results.json`
2. `validation_results.json`

The `sample_block_validation_results.json` prepends a dummy messages to the user story. The dummy messages act as context. The goal is to validate if the external agent can properly handle an array of messages where the n-1 messages is the context, and the nth message is the message the external agent should respond to provided the context. The following dummy messages are prepended:

```python
MESSAGES = [
    {"role": "user", "content": "what's the holiday is June 13th in us?"},
    {"role": "assistant", "content": "tool_name: calendar_lookup, args {\"location\": \"USA\", \"data\": \"06-13-2025\"}}"},
    {"role": "assistant", "content":"it's National Sewing Machine Day"}
]
```

The validation files contain the following fields:

1. success - boolean to indicate if the events streamed back adhered to the schema 
2. logged-events - streamed events from the external agent
3. messages - the messages that were sent to the external agent.

## Evaluating the External Agent
After validation, you can evaluate the external agent using the provided input.

### Running the Evaluation
1. Import the external agent to your tenant. See the [documentation](https://developer.watson-orchestrate.ibm.com/agents/build_agent#provider%3A-external-chat) for an in depth guide. For example,

```bash
orchestrate agents import -f ./examples/evaluations/external_agent_validation/sample.yaml 
orchestrate agents list # external agent listed under `External Agents` table 
```

2. Add the external agent as a collaborator to your native agent. See the [documentation](https://developer.watson-orchestrate.ibm.com/agents/build_agent#native-agents) for an in depth guide. For example, the native agent spec can look like

```json
{
   "spec_version": "v1",
   "style": "default",
   "llm": "watsonx/meta-llama/llama-3-405b-instruct",
   "name": "<provide name for native agent>",
   "description": "<provide description for your native agent>",
   "instructions": "<provide instructions for your native agent>",
   "collaborators": ["QA_Agent"] // must match the `name` field from external agent spec
}
```

3. Import native agent
```bash
orchestrate agents import -f ./examples/evaluations/external_agent_validation/native_agent.json 
orchestrate agents list # native agent listed under `Agents` table along with the external agent under the `Collaborators` column
```

4. Run the evaluation

```bash
orchestrate evaluations validate-external --agent_name "<name of native agent>" --tsv "./examples/evaluations/external_agent_validation/test.tsv" --external-agent-config "./examples/evaluations/external_agent_validation/sample.yaml"
```

This runs the evaluation framework against provided user stories.
